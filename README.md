# Simulate and Recover Background & Description
#### EZ diffusion is the simplification of drift diffusion. Drift diffusion is a common model in CogSci for analyzing a decision making process based on response times and accuracy. It is an effective model for this because it can successfully recover our key parameters: drift rate(v), boundary separation (a) and non decision time(t).

#### The process begins with selecting a set of true parameters and the sample size. Using the forward equations we can generate predicted summary statistics which give us the accuracy rate. The mean RT, and the RT variance. Because of the noise found in real world data, our observed data won’t always match the prediction our equation makes. To account for that difference, we can simulate observed summary statistics using a probability distribution. For this, we can rely on realistic variability which mimics the way actual experimental data fluctuates.

#### First, the code collects some summary statistics from the data. Then, the EZ diffusion model works backward and estimates the original values. These estimates (vestv_{est}, aesta_{est}, testt_{est}) are compared to the actual values to see how close they are. To check accuracy, we look at bias (b)—which shows how far off the estimates are—and squared error (b2b^2), which measures how big the mistakes are. If bias averages to zero and squared error gets smaller when sample size increases, that means the model is effective.

#### The results show that more data leads to better estimates. With only N = 10 samples, the estimates are not very good. One value, boundary separation (α), is way too low—about 1.13 below the true value. The other two values, drift rate (ν) and nondecision time (τ), are also off, but not as much. The squared errors are large, meaning the model’s guesses aren’t very reliable when there’s not enough data.

#### When we increase the sample size to N = 40, the estimates improve. The values for drift rate (ν) and nondecision time (τ) get much closer to the correct numbers, but boundary separation (α) is still a little too low. The squared errors also shrink, meaning the model is making better guesses.

#### With N = 4000, the estimates are the best they can be. Bias is almost zero for all three values, and squared errors are tiny. This shows that when we have a lot of data, the model can correctly figure out the original values with very little error. This matches what we expect: more data makes estimates more accurate.

#### Overall, these results show a clear pattern: small datasets lead to big errors, while large datasets give much better estimates. The EZ diffusion model is a fast and simple way to estimate cognitive parameters, but it only works well when there’s enough data. If researchers use it with very small datasets, the mistakes could be big enough to cause misleading results